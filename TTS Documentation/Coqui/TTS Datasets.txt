TTS Datasets
Some of the known public datasets that we successfully applied üê∏TTS:

English - LJ Speech

The LJ Speech Dataset
This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. A transcription is provided for each clip. Clips vary in length from 1 to 10 seconds and have a total length of approximately 24 hours.

The texts were published between 1884 and 1964, and are in the public domain. The audio was recorded in 2016-17 by the LibriVox project and is also in the public domain.

Download Dataset (2.6 GB)

Sample Data
The examination and testimony of the experts enabled the Commission to conclude that five shots may have been fired,

Many animals of even complex structure which live parasitically within others are wholly devoid of an alimentary cavity.

File Format
Metadata is provided in transcripts.csv. This file consists of one record per line, delimited by the pipe character (0x7c). The fields are:

ID: this is the name of the corresponding .wav file
Transcription: words spoken by the reader (UTF-8)
Normalized Transcription: transcription with numbers, ordinals, and monetary units expanded into full words (UTF-8).
Each audio file is a single-channel 16-bit PCM WAV with a sample rate of 22050 Hz.

Statistics
Total Clips	13,100
Total Words	225,715
Total Characters	1,308,678
Total Duration	23:55:17
Mean Clip Duration	6.57 sec
Min Clip Duration	1.11 sec
Max Clip Duration	10.10 sec
Mean Words per Clip	17.23
Distinct Words	13,821
Miscellaneous
The audio clips range in length from approximately 1 second to 10 seconds. They were segmented automatically based on silences in the recording. Clip boundaries generally align with sentence or clause boundaries, but not always.
The text was matched to the audio manually, and a QA pass was done to ensure that the text accurately matched the words spoken in the audio.
The original LibriVox recordings were distributed as 128 kbps MP3 files. As a result, they may contain artifacts introduced by the MP3 encoding.
The following abbreviations appear in the text. They may be expanded as follows:
Abbreviation	Expansion
Mr.	Mister
Mrs.	Misess (*)
Dr.	Doctor
No.	Number
St.	Saint
Co.	Company
Jr.	Junior
Maj.	Major
Gen.	General
Drs.	Doctors
Rev.	Reverend
Lt.	Lieutenant
Hon.	Honorable
Sgt.	Sergeant
Capt.	Captain
Esq.	Esquire
Ltd.	Limited
Col.	Colonel
Ft.	Fort
(*) there's no standard expansion for "Mrs."

19 of the transcriptions contain non-ASCII characters (for example, LJ016-0257 contains "raison d'√™tre").
Example code using this dataset to train a speech synthesis model can be found at: github.com/keithito/tacotron.
For more information or to report errors, please email kito@kito.us.
Changelog
1.1 (current release)
Version 1.0 included 30 .wav files without corresponding annotations in metadata.csv. These have been removed in version 1.1. Thanks to Rafael Valle for spotting this.
1.0
Initial release
License
This dataset is in the public domain in the US (and most likely other countries as well). There are no restrictions on its use. For more information, please see: librivox.org/pages/public-domain.

Credits
This dataset consists of excerpts from the following works:

Morris, William, et al. Arts and Crafts Essays. 1893.
Griffiths, Arthur. The Chronicles of Newgate, Vol. 2. 1884.
Roosevelt, Franklin D. The Fireside Chats of Franklin Delano Roosevelt. 1933-42.
Harland, Marion. Marion Harland's Cookery for Beginners. 1893.
Rolt-Wheeler, Francis. The Science - History of the Universe, Vol. 5: Biology. 1910.
Banks, Edgar J. The Seven Wonders of the Ancient World. 1916.
President's Commission on the Assassination of President Kennedy. Report of the President's Commission on the Assassination of President Kennedy. 1964.
Recordings by Linda Johnson from LibriVox. Alignment and annotation by Keith Ito. All text, audio, and annotations are in the public domain. We request that you use this dataset for good and not evil.

As this work is in the public domain, you may use it without attribution. However, if you'd like to cite it in a publication, please do so by linking to this page or using the following:

@misc{ljspeech17,
  author       = {Keith Ito and Linda Johnson},
  title        = {The LJ Speech Dataset},
  howpublished = {\url{https://keithito.com/LJ-Speech-Dataset/}},
  year         = 2017
}

English - Nancy

Lessac Technologies, Inc. voice release for Blizzard 2011
These data were made available to registered participants in the Blizzard Challenge 2011 and are now available generally.
Speech data
This data is released under a license for non-commercial use only. Read and accept the license. Once we have received your registration and your license, we will email you a password. All requests are manually checked.

Information about the speaker
The speaker is Nancy Krebs, who is a professional voice coach. She has a US English accent.
The Voice Works, Nancy Krebs' voice training and coaching company
Lessac Technologies Inc.
The Lessac Institute
Downloads
The data comprises:
16k prompts in wave file format
pitch marks for 16k wave files
prompts in text format
automated label files in Lesseme format (a prosodic phoneme set of 800+ labels), as produced by the Lessac front-end, including segmentation boundaries
corrected labels (i.e. for a few labels, the correct Lesseme label is different than that produced by the Front-end due to Front-end issues or Voice actor issues ) - these may or may not be useful to participants
Lesseme descriptions and a mapping description to go from Lessemes to other phoneme sets
original unsplit full fidelity wave files (one studio session was at 44.1K, the rest at 96K)
The following files are available to download from here:
wavn.tgz - Tarred archive of the prompts in the Nancy corpus, at 16KHz sampling rate, with each file name as used in the Nancy corpus.
Nancy3AsciiPitchmarkers.zip - Zipped set of files with pitch marks in ascii format. The header in each file describes the format.
prompts.data - File with all of the prompt texts in filename order.
corrected.gui - File with all of the prompts in Lesseme labeled format in the order of the Nancy corpus as originally recorded, after some labels produced by the Lessac Front-end were corrected to reflect what the voice actor actually said.
uncorrected.gui - File with all of the prompts in Lesseme labeled format in the order of the Nancy corpus as produced by the Lessac Front-end from the prompts.data file without correction to the labels for what the voice actor actually said.
lab.ssil.zip - Zipped set of files with Lesseme labels that include the result of automated segmentation of the Lesseme labels in the corrected.gui file before the ssil label is collapsed into the preceding or following label.
lab.zip - Zipped set of files with Lesseme labels that include the result of automated segmentation of the labels in the corrected.gui file after the ssil label is collapsed into the preceding or following label.
Lessemes.zip - Zipped set of files with descriptions of the Lesseme labeling methodology.
NancyCorpusToArchiveMap.xls - Mapping of the Nancy Corpus filenames to the file recording order used in the sound studio reflected in the two Archive zip files. Please note there are two prompt files missing from the archive, and one duplicate. Each is noted and explained in the Exceptions column.
as well as the following files which participants may find useful:
96k_wav_part_[1-4].tar.bz2 - the original studio recordings at 96KHz, with each prompt separated by a pure tone, and named sequentially
44k_wav.tar.bz2 - the original studio recordings downsampled to 44.1KHz, with each prompt separated by a pure tone, and named sequentially.
md5 checksums for the files are as follows:
	dd633a50bc40c690e89dafa9a2c2769a  44k_wav.tar.bz2

	1ce493db881fd50fc1006e8c51fd527d  96k_wav_part_1.tar.bz2
	bb32ae158aa97a3e39c50f7811f425bf  96k_wav_part_2.tar.bz2
	6007ce1b5b186cad0740155f533fd5ab  96k_wav_part_3.tar.bz2
	be322bace2e19c2bd08376b78023fb39  96k_wav_part_4.tar.bz2

	ec2bbd518751cb350680b66833e61411  corrected.gui
	0a4860a69bca56d7e9f8170306ff3709  lab.ssil.zip
	aeae7916d881a8eef255a6fe05e77e77  lab.zip
	e5c8afeaa8c6517e9980268dc2705ad7  Lessemes.zip
	292157e81dbc93944bbcf5b1ae61f638  Nancy3AsciiPitchmarkers.zip
	9e91f5076c3cb6246e9881ceb7581d21  NancyCorpusToArchiveMap.xls
	650b44f7252aed564d190b76a98cb490  prompts.data
	a370e4715e95b227503f371ecfd1a518  uncorrected.gui
	bb2a80dd1423f87ba12d2074af8e7a3f  wavn.tgz
and the sizes of the large files are:
	3.8G    44k_wav.tar.bz2
	5.3G    96k_wav_part_1.tar.bz2
	4.6G    96k_wav_part_2.tar.bz2
	3.9G    96k_wav_part_3.tar.bz2
	3.9G    96k_wav_part_4.tar.bz2
	1.6G    wavn.tgz
Front end
Lessac Technologies Inc. have made their front end available via the internet. Some notes on usage and restrictions can be found in the file lessac_front_end_instructions.html which is available after you obtain a license for the data.

Contact Simon King for more details.

English - TWEB

The World English Bible
A large, single-speaker speech dataset in English

About Dataset
Context
The World English Bible is a public domain update of the American Standard Version of 1901 into modern English. Its audio recordings are freely available at http://www.audiotreasure.com/. The only problem when you use those in speech-relevant tasks is that each file is too long. That's why I split each audio file such that an audio clip is equivalent to a verse. Subsequently I aligned them to the text.

Content
This dataset is composed of the following:

README.md
wav files sampled at 12,000 KHZ
transcript.txt.

transcript.txt is in a tab-delimited format. The first column is the audio file paths. The second one is the script. Finally, the rightmost column is the duration of the audio file.

Acknowledgements
I would like to show my respect to Dave, the host of www.audiotreasure.com and the reader of the audio files.

Reference
You may want to check my project using this dataset at https://github.com/Kyubyong/tacotron.

English - LibriTTS

[LibriTTS corpus
Identifier: SLR60

Summary: Large-scale corpus of English speech derived from the original materials of the LibriSpeech corpus

Category: Speech

License: CC BY 4.0

Downloads (use a mirror closer to you):
dev-clean.tar.gz [1.2G]   ( Development set, clean speech )   Mirrors: [EU]   [EU]   [CN]  
dev-other.tar.gz [924M]   ( Development set, more challenging speech )   Mirrors: [EU]   [EU]   [CN]  
test-clean.tar.gz [1.2G]   ( Test set, "clean" speech )   Mirrors: [EU]   [EU]   [CN]  
test-other.tar.gz [964M]   ( Test set, "other" speech )   Mirrors: [EU]   [EU]   [CN]  
train-clean-100.tar.gz [7.7G]   ( Training set derived from the original materials of the train-clean-100 subset of LibriSpeech )   Mirrors: [EU]   [EU]   [CN]  
train-clean-360.tar.gz [27G]   ( Training set derived from the original materials of the train-clean-360 subset of LibriSpeech )   Mirrors: [EU]   [EU]   [CN]  
train-other-500.tar.gz [44G]   ( Training set derived from the original materials of the train-other-500 subset of LibriSpeech )   Mirrors: [EU]   [EU]   [CN]  


About this resource:

LibriTTS is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate, prepared by Heiga Zen with the assistance of Google Speech and Google Brain team members. The LibriTTS corpus is designed for TTS research. It is derived from the original materials (mp3 audio files from LibriVox and text files from Project Gutenberg) of the LibriSpeech corpus. The main differences from the LibriSpeech corpus are listed below:
The audio files are at 24kHz sampling rate.
The speech is split at sentence breaks.
Both original and normalized texts are included.
Contextual information (e.g., neighbouring sentences) can be extracted.
Utterances with significant background noise are excluded.
For more information, refer to the paper "LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J. Weiss, Ye Jia, Zhifeng Chen, and Yonghui Wu, arXiv, 2019. If you use the LibriTTS corpus in your work, please cite this paper where it was introduced.
The MD5 checksums of the downloads are as follows (note: not everyone will want to know this).


0c3076c1e5245bb3f0af7d82087ee207  dev-clean.tar.gz
815555d8d75995782ac3ccd7f047213d  dev-other.tar.gz
7bed3bdb047c4c197f1ad3bc412db59f  test-clean.tar.gz
ae3258249472a13b5abef2a816f733e4  test-other.tar.gz
4a8c202b78fe1bc0c47916a98f3a2ea8  train-clean-100.tar.gz
a84ef10ddade5fd25df69596a2767b2d  train-clean-360.tar.gz
7b181dd5ace343a5f38427999684aa6f  train-other-500.tar.gz
]

English - VCTK
[VCTK
Full Text Search:


 
The collection's logo

CSTR's VCTK Corpus (Centre for Speech Technology Voice Cloning Toolkit) includes speech data uttered by 109 native speakers of English with various accents. Each speaker reads out about 400 sentences, most of which were selected from a newspaper plus the Rainbow Passage and an elicitation paragraph intended to identify the speaker's accent. The newspaper texts were taken from The Herald (Glasgow), with permission from Herald & Times Group. Each speaker reads a different set of the newspaper sentences, where each set was selected using a greedy algorithm designed to maximise the contextual and phonetic coverage. The Rainbow Passage and elicitation paragraph are the same for all speakers. This corpus was recorded for the purpose of building HMM-based text-to-speech synthesis systems, especially for speaker-adaptive HMM-based speech synthesis using average voice models trained on multiple speakers and speaker adaptation technologies. The file was previously available on the CSTR website, and was referenced in the Google DeepMind work on WaveNet: https://arxiv.org/pdf/1609.03499.pdf .

Image: Detail showing a rainbow from "Late Autumn Landscape, Cambuskenneth" by Thomas Fenwick ¬© The University of Edinburgh, all rights reserved. (N.B. Recordings include The Rainbow Passage.)

Items in this Collection
No Thumbnail [100%x80]
CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92) Ôªø
Yamagishi, Junichi; Veaux, Christophe; MacDonald, Kirsten
This CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents. Each speaker reads out about 400 sentences, which were selected from a newspaper, the rainbow passage and an elicitation ...
No Thumbnail [100%x80]
Device Recorded VCTK (Small subset version) Ôªø
Sarfjoo, Seyyed Saeed; Yamagishi, Junichi
This dataset is a new variant of the voice cloning toolkit (VCTK) dataset: device-recorded VCTK (DR-VCTK), where the high-quality speech signals recorded in a semi-anechoic chamber using professional audio devices are ...
No Thumbnail [100%x80]
SUPERSEDED - Device Recorded VCTK (Small subset version) Ôªø
Sarfjoo, Seyyed Saeed; Yamagishi, Junichi
## This item has been replaced by the one which can be found at https://doi.org/10.7488/ds/2316 ## This dataset is a new variant of the voice cloning toolkit (VCTK) dataset: device-recorded VCTK (DR-VCTK), where the ...
No Thumbnail [100%x80]
Noisy reverberant speech database for training speech enhancement algorithms and TTS models Ôªø
Valentini-Botinhao, Cassia
Noisy reverberant speech database. The database was designed to train and test speech enhancement (noise suppression and dereverberation) methods that operate at 48kHz. Clean speech was made reverberant and noisy by ...
No Thumbnail [100%x80]
Noisy speech database for training speech enhancement algorithms and TTS models Ôªø
Valentini-Botinhao, Cassia
Clean and noisy parallel speech database. The database was designed to train and test speech enhancement methods that operate at 48kHz. A more detailed description can be found in the papers associated with the database. ...
No Thumbnail [100%x80]
96kHz version of the CSTR VCTK Corpus Ôªø
Veaux, Christophe; Yamagishi, Junichi
This dataset includes 96kHz version of the CSTR VCTK Corpus including speech data uttered by 109 native speakers of English with various accents. The main dataset can be found at https://doi.org/10.7488/ds/1994 (containing ...
No Thumbnail [100%x80]
SUPERSEDED - CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit Ôªø
Veaux, Christophe; Yamagishi, Junichi; MacDonald, Kirsten
## This item has been replaced by the one which can be found at https://doi.org/10.7488/ds/2645 ##' This CSTR VCTK Corpus (Centre for Speech Technology Voice Cloning Toolkit) includes speech data uttered by 109 native ...
No Thumbnail [100%x80]
SUPERSEDED - CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit Ôªø
Veaux, Christophe; Yamagishi, Junichi; MacDonald, Kirsten
# SUPERSEDED - This item has been replaced by the one which can be found at https://doi.org/10.7488/ds/1994 . # This CSTR VCTK Corpus (Centre for Speech Technology Voice Cloning Toolkit) includes speech data uttered by 109 ...
No Thumbnail [100%x80]
Reverberant speech database for training speech dereverberation algorithms and TTS models Ôªø
Valentini-Botinhao, Cassia
Reverberant speech database. The database was designed to train and test speech dereverberation methods that operate at 48kHz. Clean speech was made reverberant by convolving it with a room impulse response. The room impulse ...
 ][CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92)
No Thumbnail [100%x80]
Date Available
2019-11-13
Type
sound
Data Creator
Yamagishi, Junichi
Veaux, Christophe
MacDonald, Kirsten
Publisher
University of Edinburgh. The Centre for Speech Technology Research (CSTR)
Relation (Is Version Of)
http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html
Relation (Is Referenced By)
https://arxiv.org/pdf/1609.03499.pdf
Metadata
Show full item record
Altmetric
Article has an altmetric score of 9

Citation
Yamagishi, Junichi; Veaux, Christophe; MacDonald, Kirsten. (2019). CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92), [sound]. University of Edinburgh. The Centre for Speech Technology Research (CSTR). https://doi.org/10.7488/ds/2645.
Description
This CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents. Each speaker reads out about 400 sentences, which were selected from a newspaper, the rainbow passage and an elicitation paragraph used for the speech accent archive. The newspaper texts were taken from Herald Glasgow, with permission from Herald & Times Group. Each speaker has a different set of the newspaper texts selected based a greedy algorithm that increases the contextual and phonetic coverage. The details of the text selection algorithms are described in the following paper: C. Veaux, J. Yamagishi and S. King, "The voice bank corpus: Design, collection and data analysis of a large regional accent speech database," https://doi.org/10.1109/ICSDA.2013.6709856 The rainbow passage and elicitation paragraph are the same for all speakers. The rainbow passage can be found at International Dialects of English Archive: (http://web.ku.edu/~idea/readings/rainbow.htm). The elicitation paragraph is identical to the one used for the speech accent archive (http://accent.gmu.edu). The details of the the speech accent archive can be found at http://www.ualberta.ca/~aacl2009/PDFs/WeinbergerKunath2009AACL.pdf All speech data was recorded using an identical recording setup: an omni-directional microphone (DPA 4035) and a small diaphragm condenser microphone with very wide bandwidth (Sennheiser MKH 800), 96kHz sampling frequency at 24 bits and in a hemi-anechoic chamber of the University of Edinburgh. (However, two speakers, p280 and p315 had technical issues of the audio recordings using MKH 800). All recordings were converted into 16 bits, were downsampled to 48 kHz, and were manually end-pointed. This corpus was originally aimed for HMM-based text-to-speech synthesis systems, especially for speaker-adaptive HMM-based speech synthesis that uses average voice models trained on multiple speakers and speaker adaptation technologies. This corpus is also suitable for DNN-based multi-speaker text-to-speech synthesis systems and neural waveform modeling. The dataset was was referenced in the Google DeepMind work on WaveNet: https://arxiv.org/pdf/1609.03499.pdf . Please note while text files containing transcripts of the speech are provided for 109 of the 110 recordings, in the '/txt' folder, the 'p315' text was lost due to a hard disk error.]

Multilingual - M-AI-Labs

Spanish - thx! @carlfm01

German - Thorsten OGVD

Japanese - Kokoro [Skip to
content
Kaggle

Create
Home

Competitions

Datasets

Models

Benchmarks

Game Arena

Code

Discussions

Learn

More


View Active Events

Search


Sign In

Register
Katsuya Iida ¬∑ Updated 5 years ago
Kokoro Speech Dataset v1.1 Small
A single speaker Japanese speech dataset

Kokoro Speech Dataset v1.1 Small

Code

Download
About Dataset
Kokoro Speech Dataset
Kokoro Speech Dataset is a public domain Japanese speech dataset.
It contains 43,253 short audio clips of a single speaker reading 14 novel books.
The format of the metadata is similar to that of
LJ Speech so that the dataset is compatible
with modern speech synthesis systems.

The texts are from
Aozora Bunko,
which is in the public domain. The audio clips
are from
LibriVox project,
which is also in the public domain.
Readings are estimated by
MeCab
and
UniDic Lite
from kanji-kana mixture text.
Readings are romanized
which are similar to the format used by
Julius.

The audio clips were split and transcripts were aligned automatically by
Voice100.

Sample data
Listen
from your browser or download
randomly sampled 100 clips.

File Format
Metadata is provided in metadata.csv. This file consists of one record per line,
delimited by the pipe character (0x7c). The fields are:

ID: this is the name of the corresponding .wav file
Transcription: Kanji-kana mixture text spoken by the reader (UTF-8)
Reading: Romanized text spoken by the reader (UTF-8)
Each audio file is a single-channel 16-bit PCM WAV with a sample rate of 22050 Hz.

Statistics
The dataset is provided in different sizes, xlarge, large, small, tiny.
large, small and tiny don't share same clips.
xlarge contains all available clips, including large, small and tiny.

X Large:
Total clips: 43253
Min duration: 3.007 secs
Max duration: 14.988 secs
Mean duration: 4.993 secs
Total duration: 59:59:40

Large:
Total clips: 22910
Min duration: 3.007 secs
Max duration: 14.988 secs
Mean duration: 4.984 secs
Total duration: 31:42:54

Small:
Total clips: 8812
Min duration: 3.007 secs
Max duration: 14.431 secs
Mean duration: 4.951 secs
Total duration: 12:07:12

Tiny:
Total clips: 285
Min duration: 3.019 secs
Max duration: 9.462 secs
Mean duration: 4.871 secs
Total duration: 00:23:08
How to get the data
Because of its large data size of the dataset, audio files are not
included in this repository, but the metadata is included.

To make .wav files of the dataset, run

$ bash download.sh
to download the metadata from the project page. Then run

$ pip3 install torchaudio
$ python3 extract.py --size tiny
This prints a shell script example to download MP3 audio files
from archive.org and extract them if you haven't done it already.

After doing so, run the command again

$ python3 extract.py --size tiny
to get files for tiny under ./output directory.

You can give another size name to the --size option to get
dataset of the size.

Pretrained Tacotron model
Audio Samples
Pretrained model
Pretrained Tacotron
model trained with Kokoro Speech Dataset
and audio samples are available.
The model was trained for 21K steps with small.
According to the above repo,
"Speech started to become intelligible around 20K steps" with
LJ Speech Dataset.
Audio samples read the first few sentences from Gon Gitsune
which is not included in small.

Books
The dataset contains recordings from these books read by
ekzemplaro

ÊòéÊöó (Meian) 16:39:29
Online text
„Åì„Åì„Çç (Kokoro) 08:46:41
Online text
Áî∞ËàéÊïôÂ∏´ (Inaka Kyoshi) 08:13:26
Online text
ÈáéÂàÜ (Nowaki) 4:40:49
Online text
ËçâÊûï (Kusamakura) 04:27:35
Online text
Âùä„Å£„Å°„ÇÉ„Çì (Botchan) 04:26:27
Online text
ÈõÅ (Gan) 03:41:31
Online text
Áîü„Åæ„Çå„ÅÑ„Åö„ÇãÊÇ©„Åø (Umareizuru Nayami) 2:43:12
Online text
Á°ùÂ≠êÊà∏„ÅÆ‰∏≠ (Garasudono uchi) 2:39:53
Online text
Ê∞∏Êó•Â∞èÂìÅ (Eijitsu Syohin) 2:33:54
Online text
Ëí≤Âõ£ (Futon) 2:28:58
Online text
È´òÈáéËÅñ (Kouyahijiri) 2:06:23
Online text
„Åî„ÇìÁãê (Gon gitsune) 0:15:42
Online text
„Ç≥„Éº„Ç´„Çµ„Çπ„ÅÆÁ¶øÈ∑π (Caucasus no Hagetaka) 0:13:04
Online text
Similar project
This project was also inspired by CSS10, which
contains audio clips of various languages from LibriVox.

Changelog
v1.1 Added more books
v1.0 Current release
License
This dataset is in the public domain in the USA (and most likely other countries as well).
There are no restrictions on its use. For more information, please see:
librivox.org/pages/public-domain.


View less
Usability
7.06

License
CC0: Public Domain

Expected update frequency
Not specified

Tags
Arts and Entertainment
Literature
Audio
Japan
__notebook_source__.ipynb(263 B)
{
  "cells": [],
  "metadata": {
    "language_info": {
      "name": "none",
      "version": "0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
Data Explorer
1.93 GB

wavs

__notebook_source__.ipynb

metadata.csv

Summary
8814 files

3 columns

See what others are saying about this dataset
What have you used this dataset for?

Learning 0

Research 0

Application 0

LLM Fine-Tuning 0
How would you describe this dataset?

Well-documented 0

Well-maintained 0

Clean data 0

Original 0

High-quality notebooks 0

Other
Metadata

Collapse All
Collaborators
Katsuya Iida (Owner)

Authors
Author Name
-

Bio
-

Coverage
Temporal Coverage Start Date
-

Temporal Coverage End Date
-

Geospatial Coverage
-

DOI Citation
DOI (Digital Object Identifier)
-

Provenance
Sources
From notebook: [Private Notebook]
Collection Methodology
-

Citations
This dataset does not have any citations yet.

License
CC0: Public Domain
Expected Update Frequency
Not specified (Updated 5 years ago)

Activity Overview
Views
6845
date	Views
Nov 15, 2025	2
Nov 16, 2025	2
Nov 17, 2025	2
Nov 18, 2025	8
Nov 19, 2025	1
Nov 20, 2025	3
Nov 21, 2025	2
Nov 22, 2025	3
Nov 23, 2025	4
Nov 24, 2025	1
Nov 25, 2025	9
Nov 27, 2025	7
Nov 28, 2025	5
Nov 29, 2025	1
Dec 2, 2025	5
Dec 3, 2025	4
Dec 4, 2025	2
Dec 6, 2025	4
Dec 7, 2025	4
Dec 8, 2025	4
Dec 9, 2025	2
Dec 10, 2025	3
Dec 13, 2025	3
date	Views
Nov 15, 2025	2
Nov 16, 2025	2
Nov 17, 2025	2
Nov 18, 2025	8
Nov 19, 2025	1
Nov 20, 2025	3
Nov 21, 2025	2
Nov 22, 2025	3
Nov 23, 2025	4
Nov 24, 2025	1
Nov 25, 2025	9
Nov 27, 2025	7
Nov 28, 2025	5
Nov 29, 2025	1
Dec 2, 2025	5
Dec 3, 2025	4
Dec 4, 2025	2
Dec 6, 2025	4
Dec 7, 2025	4
Dec 8, 2025	4
Dec 9, 2025	2
Dec 10, 2025	3
Dec 13, 2025	3
81
in the last 30 days
Downloads
567
date	Downloads
Nov 18, 2025	1
Nov 25, 2025	1
Nov 29, 2025	1
Dec 7, 2025	1
Dec 9, 2025	1
date	Downloads
Nov 18, 2025	1
Nov 25, 2025	1
Nov 29, 2025	1
Dec 7, 2025	1
Dec 9, 2025	1
5
in the last 30 days
Engagement
0.08283
downloads per view
Comments
0
posted
Top Contributors
No Data

Detail View
Views
[object Object]
11/17
11/24
12/01
12/08
0
5
10
date	Views
Nov 15, 2025	2
Nov 16, 2025	2
Nov 17, 2025	2
Nov 18, 2025	8
Nov 19, 2025	1
Nov 20, 2025	3
Nov 21, 2025	2
Nov 22, 2025	3
Nov 23, 2025	4
Nov 24, 2025	1
Nov 25, 2025	9
Nov 27, 2025	7
Nov 28, 2025	5
Nov 29, 2025	1
Dec 2, 2025	5
Dec 3, 2025	4
Dec 4, 2025	2
Dec 6, 2025	4
Dec 7, 2025	4
Dec 8, 2025	4
Dec 9, 2025	2
Dec 10, 2025	3
Dec 13, 2025	3
date	Views
Nov 15, 2025	2
Nov 16, 2025	2
Nov 17, 2025	2
Nov 18, 2025	8
Nov 19, 2025	1
Nov 20, 2025	3
Nov 21, 2025	2
Nov 22, 2025	3
Nov 23, 2025	4
Nov 24, 2025	1
Nov 25, 2025	9
Nov 27, 2025	7
Nov 28, 2025	5
Nov 29, 2025	1
Dec 2, 2025	5
Dec 3, 2025	4
Dec 4, 2025	2
Dec 6, 2025	4
Dec 7, 2025	4
Dec 8, 2025	4
Dec 9, 2025	2
Dec 10, 2025	3
Dec 13, 2025	3
Downloads
[object Object]
11/19
11/21
11/23
11/25
11/27
11/29
12/01
12/03
12/05
12/07
12/09
0
1
2
date	Downloads
Nov 18, 2025	1
Nov 25, 2025	1
Nov 29, 2025	1
Dec 7, 2025	1
Dec 9, 2025	1
date	Downloads
Nov 18, 2025	1
Nov 25, 2025	1
Nov 29, 2025	1
Dec 7, 2025	1
Dec 9, 2025	1
Similar Datasets

Aozora Bunko Text Difficulty
Ronan Takizawa
Usability 7.1 ¬∑ Updated 14 days ago
1 File (CSV) ¬∑ 62 MB
1

wsdm - open models - nbroad
Nicholas Broad
Usability 10.0 ¬∑ Updated a year ago
3 Files (other) ¬∑ 47 MB ¬∑ 512 downloads
28


Kc-MoE Pretrain & Finetune Dataset
Quasar Kim
Usability 6.3 ¬∑ Updated 3 years ago
28 GB ¬∑ 50 downloads
0

Common Lit Samples
AyushS9020
Usability 5.0 ¬∑ Updated 2 years ago
91 MB ¬∑ 14 downloads
1
]

Chinese

Ukrainian - LADA